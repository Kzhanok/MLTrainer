{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLFLOW_TRACKING_URI=sqlite:///mlruns.db\n"
     ]
    }
   ],
   "source": [
    "%env MLFLOW_TRACKING_URI=sqlite:///mlruns.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Adding dropout and normalization layers\n",
    "Study the pytorch documentation for:\n",
    "- Dropout https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "- normalization layers https://pytorch.org/docs/stable/nn.html#normalization-layers\n",
    "\n",
    "Experiment with adding dropout and normalization layers to your model. Some rough guidelines where to add them relative to Linear or Conv2d layers:\n",
    "- Dropout: after Linear or Conv2d layers. Often added after the last Linear layer *before* the output layer, but could occur more often.\n",
    "- Normalization layers: right after (blocks of) Linear or Conv2d layers, but before activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-23 17:01:03.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\leons\\.cache\\mads_datasets\\flowers\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "batchsize = 64\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-23 17:04:52.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_flattened_size\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mOutput shape after convolutions: torch.Size([1, 256, 3, 3])\u001b[0m\n",
      "\u001b[32m2024-09-23 17:04:52.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mFlattened size for the first Linear layer: 2304\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 128, 112, 112]           3,584\n",
      "       BatchNorm2d-2        [-1, 128, 112, 112]             256\n",
      "              ReLU-3        [-1, 128, 112, 112]               0\n",
      "           Dropout-4        [-1, 128, 112, 112]               0\n",
      "         MaxPool2d-5          [-1, 128, 28, 28]               0\n",
      "            Conv2d-6          [-1, 256, 13, 13]         295,168\n",
      "       BatchNorm2d-7          [-1, 256, 13, 13]             512\n",
      "              ReLU-8          [-1, 256, 13, 13]               0\n",
      "           Dropout-9          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-10            [-1, 256, 3, 3]               0\n",
      "          Flatten-11                 [-1, 2304]               0\n",
      "           Linear-12                  [-1, 128]         295,040\n",
      "      BatchNorm1d-13                  [-1, 128]             256\n",
      "             ReLU-14                  [-1, 128]               0\n",
      "          Dropout-15                  [-1, 128]               0\n",
      "           Linear-16                   [-1, 64]           8,256\n",
      "      BatchNorm1d-17                   [-1, 64]             128\n",
      "             ReLU-18                   [-1, 64]               0\n",
      "          Dropout-19                   [-1, 64]               0\n",
      "           Linear-20                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 603,850\n",
      "Trainable params: 603,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 51.13\n",
      "Params size (MB): 2.30\n",
      "Estimated Total Size (MB): 54.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from loguru import logger\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, filters: int, units1: int, units2: int, input_size: tuple):\n",
    "        super().__init__()\n",
    "        self.in_channels = input_size[1]\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, filters, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=4),  # Output size halved\n",
    "            nn.Conv2d(filters, filters*2, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(filters*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=4),  # Output size halved again\n",
    "            # Output size halved once more\n",
    "        )\n",
    "\n",
    "        # Calculate the flattened size based on actual output shape after convolutions\n",
    "        flattened_size = self._get_flattened_size(input_size)\n",
    "        logger.info(f\"Flattened size for the first Linear layer: {flattened_size}\")\n",
    "\n",
    "        # Remove AdaptiveAvgPool2d, as the tensor is already reduced\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten the 2D to 1D\n",
    "            nn.Linear(flattened_size, units1),  # Input size should match the flattened size\n",
    "            nn.BatchNorm1d(units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.BatchNorm1d(units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(units2, 10)  # Output 10 classes\n",
    "        )\n",
    "\n",
    "    # This function calculates the flattened size after convolutions\n",
    "    def _get_flattened_size(self, input_size):\n",
    "        x = torch.ones(1, *input_size[1:], dtype=torch.float32)  # Add batch dimension\n",
    "        x = self.convolutions(x)\n",
    "        logger.info(f\"Output shape after convolutions: {x.shape}\")\n",
    "        return x.numel()  # Return the total number of elements (flattened size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.dense(x)  # Forward to dense layers\n",
    "        return x\n",
    "\n",
    "# Define the model\n",
    "model = CNN(filters=128, units1=128, units2=64, input_size=(32, 3, 224, 224))\n",
    "\n",
    "# Print the model summary\n",
    "summary(model, input_size=(3, 224, 224), device='cpu')  # Correct input size for summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer.trainer import TrainerSettings, ReportTypes\n",
    "from mltrainer import metrics\n",
    "log_dir = Path(\"../../models/cnn\").resolve()\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "accuracy = metrics.Accuracy()\n",
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-23 17:03:57.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to C:\\Users\\leons\\OneDrive\\Bureaublad\\School\\models\\cnn\\20240923-170357\u001b[0m\n",
      "\u001b[32m2024-09-23 17:03:57.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import metrics\n",
    "from mltrainer.trainer import Trainer\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|\u001b[38;2;30;71;6m‚ñè         \u001b[0m| 1/45 [00:15<11:11, 15.26s/it]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/10 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leons\\OneDrive\\Bureaublad\\School\\ML Trainer\\.venv\\lib\\site-packages\\mltrainer\\trainer.py:90\u001b[0m, in \u001b[0;36mTrainer.loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mepochs), colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#1e4706\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 90\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m         metric_dict, test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalbatches()\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(epoch, train_loss, test_loss, metric_dict)\n",
      "File \u001b[1;32mc:\\Users\\leons\\OneDrive\\Bureaublad\\School\\ML Trainer\\.venv\\lib\\site-packages\\mltrainer\\trainer.py:124\u001b[0m, in \u001b[0;36mTrainer.trainbatches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 124\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    125\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m train_steps\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Personal notes!\n",
    "\n",
    "- Dropout is tpyically used after the activation function and before the pooling function. This is because after the pooling function there are less activation neurons to drop out. so less weights to be influenced by the dropout. Dropout is designed to randomly set a fraction of the activations to zero. Applying it after the activation function ensures that the dropout is applied to the non-linear transformed features, which helps in regularizing the network more effectively.\n",
    "Also to maintain sctructure of the network.\n",
    "\n",
    "- Stabilizing Activations: By normalizing the activations before applying the non-linearity, you ensure that the inputs to the activation functions have a consistent distribution, which helps in stabilizing the training process.\n",
    "Improving Gradient Flow: Normalization helps in maintaining a stable gradient flow through the network, which can prevent issues like vanishing or exploding gradients.\n",
    "Accelerating Training: Normalized activations can lead to faster convergence during training, as the network can learn more efficiently.\n",
    "    Why Not After Activation?\n",
    "    Placing normalization layers after the activation functions can still work, but it might not be as effective. The primary goal of normalization is to control the distribution of the inputs to the activation functions, ensuring they are within a range that the activation functions can handle well.\n",
    "\n",
    "- Adding only batch normalization layer to the model, the accuracy improved to 92.3%! re adding the dropout layers decreased performance slightly but should improve generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding convolutional and pooling layers\n",
    "Previous lessons, you have started to experiment with you model.\n",
    "You might have tested the impact of the amount of units, the depth of layers and different learning rates.\n",
    "\n",
    "This lesson, we have added some new types of layers: convolutional and pooling layers.\n",
    "Experiment with adding these new layers.\n",
    "\n",
    "Also, have a look at the `ModuleList`: https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#modulelist\n",
    "It can be really useful to create a list of layers from a configfile, and then use that list to create your model.\n",
    "Instead of just adding a single layer, you could also add a block of layers (eg a Conv2d layer, followed by a ReLU layer, followed by a BatchNorm2d layer, followed by a MaxPool2d layer) and repeat that in a loop, adding it to the `ModuleList`.\n",
    "\n",
    "# 3. Improve your pipeline\n",
    "In addition to new layers, we have expanded our logging tools with MLFlow, so we currently can choose between gin-config, tensorboard and MLFlow.\n",
    "\n",
    "Expand your training pipeline you started in the previous lesson such that:\n",
    "\n",
    "- you can switch between models by changing a config file\n",
    "- you can test different hyperparameters by changing a config file\n",
    "- you automatically log settings: model picked, hyperparameters, metrics, etc. : use either gin-config, tensorboard or MLFlow to log that, or a combination, whatever you prefer.\n",
    "- Important: doing a master means you don't just start engineering a pipeline, but you need to reflect. Why do you see the results you see? What does this mean, considering the theory? Write down lessons learned and reflections, based on experimental results.\n",
    "- continuously improve your code: \n",
    "    - clean up your experimental environment, such that it doesnt get too messy\n",
    "    - automate the boring stuff: use a Makefile, use configfiles, automate logging, etc.\n",
    "    - use git: commit your changes often and with descriptive messages\n",
    "    - separate code for pipelines, configs, models, modeltraining and results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
